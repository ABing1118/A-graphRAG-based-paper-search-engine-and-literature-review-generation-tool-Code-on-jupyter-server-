{
    title: From Local to Global: A Graph RAG Approach to Query-Focused Summarization,
    abstract: The use of retrieval-augmented generation (RAG) to retrieve relevant information from an external knowledge source enables large language models (LLMs) to answer questions over private and/or previously unseen document collections. However, RAG fails on global questions directed at an entire text corpus, such as"What are the main themes in the dataset?", since this is inherently a query-focused summarization (QFS) task, rather than an explicit retrieval task. Prior QFS methods, meanwhile, fail to scale to the quantities of text indexed by typical RAG systems. To combine the strengths of these contrasting methods, we propose a Graph RAG approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of source text to be indexed. Our approach uses an LLM to build a graph-based text index in two stages: first to derive an entity knowledge graph from the source documents, then to pregenerate community summaries for all groups of closely-related entities. Given a question, each community summary is used to generate a partial response, before all partial responses are again summarized in a final response to the user. For a class of global sensemaking questions over datasets in the 1 million token range, we show that Graph RAG leads to substantial improvements over a na\"ive RAG baseline for both the comprehensiveness and diversity of generated answers. An open-source, Python-based implementation of both global and local Graph RAG approaches is forthcoming at https://aka.ms/graphrag.,
    publicationDate: 2024-04-24,
    authors: ['Darren Edge', 'Ha Trinh', 'Newman Cheng', 'Joshua Bradley', 'Alex Chao', 'Apurva Mody', 'Steven Truitt', 'Jonathan Larson'],
    score: 144.54719949364
},
{
    title: Graph Retrieval-Augmented Generation: A Survey,
    abstract: Recently, Retrieval-Augmented Generation (RAG) has achieved remarkable success in addressing the challenges of Large Language Models (LLMs) without necessitating retraining. By referencing an external knowledge base, RAG refines LLM outputs, effectively mitigating issues such as ``hallucination'', lack of domain-specific knowledge, and outdated information. However, the complex structure of relationships among different entities in databases presents challenges for RAG systems. In response, GraphRAG leverages structural information across entities to enable more precise and comprehensive retrieval, capturing relational knowledge and facilitating more accurate, context-aware responses. Given the novelty and potential of GraphRAG, a systematic review of current technologies is imperative. This paper provides the first comprehensive overview of GraphRAG methodologies. We formalize the GraphRAG workflow, encompassing Graph-Based Indexing, Graph-Guided Retrieval, and Graph-Enhanced Generation. We then outline the core technologies and training methods at each stage. Additionally, we examine downstream tasks, application domains, evaluation methodologies, and industrial use cases of GraphRAG. Finally, we explore future research directions to inspire further inquiries and advance progress in the field. In order to track recent progress in this field, we set up a repository at \url{https://github.com/pengboci/GraphRAG-Survey}.,
    publicationDate: 2024-08-15,
    authors: ['Boci Peng', 'Yun Zhu', 'Yongchao Liu', 'Xiaohe Bo', 'Haizhou Shi', 'Chuntao Hong', 'Yan Zhang', 'Siliang Tang'],
    score: 112.49820016084324
},
{
    title: HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction,
    abstract: Extraction and interpretation of intricate information from unstructured text data arising in financial applications, such as earnings call transcripts, present substantial challenges to large language models (LLMs) even using the current best practices to use Retrieval Augmented Generation (RAG) (referred to as VectorRAG techniques which utilize vector databases for information retrieval) due to challenges such as domain specific terminology and complex formats of the documents. We introduce a novel approach based on a combination, called HybridRAG, of the Knowledge Graphs (KGs) based RAG techniques (called GraphRAG) and VectorRAG techniques to enhance question-answer (Q&A) systems for information extraction from financial documents that is shown to be capable of generating accurate and contextually relevant answers. Using experiments on a set of financial earning call transcripts documents which come in the form of Q&A format, and hence provide a natural set of pairs of ground-truth Q&As, we show that HybridRAG which retrieves context from both vector database and KG outperforms both traditional VectorRAG and GraphRAG individually when evaluated at both the retrieval and generation stages in terms of retrieval accuracy and answer generation. The proposed technique has applications beyond the financial domain,
    publicationDate: 2024-08-09,
    authors: ['Bhaskarjit Sarmah', 'Benika Hall', 'Rohan Rao', 'Sunil Patel', 'Stefano Pasquali', 'Dhagash Mehta'],
    score: 108.47424036192305
},
{
    title: Medical Graph RAG: Towards Safe Medical Large Language Model via Graph Retrieval-Augmented Generation,
    abstract: We introduce a novel graph-based Retrieval-Augmented Generation (RAG) framework specifically designed for the medical domain, called \textbf{MedGraphRAG}, aimed at enhancing Large Language Model (LLM) capabilities for generating evidence-based medical responses, thereby improving safety and reliability when handling private medical data. Graph-based RAG (GraphRAG) leverages LLMs to organize RAG data into graphs, showing strong potential for gaining holistic insights from long-form documents. However, its standard implementation is overly complex for general use and lacks the ability to generate evidence-based responses, limiting its effectiveness in the medical field. To extend the capabilities of GraphRAG to the medical domain, we propose unique Triple Graph Construction and U-Retrieval techniques over it. In our graph construction, we create a triple-linked structure that connects user documents to credible medical sources and controlled vocabularies. In the retrieval process, we propose U-Retrieval which combines Top-down Precise Retrieval with Bottom-up Response Refinement to balance global context awareness with precise indexing. These effort enable both source information retrieval and comprehensive response generation. Our approach is validated on 9 medical Q\&A benchmarks, 2 health fact-checking benchmarks, and one collected dataset testing long-form generation. The results show that MedGraphRAG consistently outperforms state-of-the-art models across all benchmarks, while also ensuring that responses include credible source documentation and definitions. Our code is released at: https://github.com/MedicineToken/Medical-Graph-RAG.,
    publicationDate: 2024-08-08,
    authors: ['Junde Wu', 'Jiayuan Zhu', 'Yunli Qi'],
    score: 99.1886522358297
},
{
    title: Retrieval-Augmented Generation with Graphs (GraphRAG),
    abstract: Retrieval-augmented generation (RAG) is a powerful technique that enhances downstream task execution by retrieving additional information, such as knowledge, skills, and tools from external sources. Graph, by its intrinsic"nodes connected by edges"nature, encodes massive heterogeneous and relational information, making it a golden resource for RAG in tremendous real-world applications. As a result, we have recently witnessed increasing attention on equipping RAG with Graph, i.e., GraphRAG. However, unlike conventional RAG, where the retriever, generator, and external data sources can be uniformly designed in the neural-embedding space, the uniqueness of graph-structured data, such as diverse-formatted and domain-specific relational knowledge, poses unique and significant challenges when designing GraphRAG for different domains. Given the broad applicability, the associated design challenges, and the recent surge in GraphRAG, a systematic and up-to-date survey of its key concepts and techniques is urgently desired. Following this motivation, we present a comprehensive and up-to-date survey on GraphRAG. Our survey first proposes a holistic GraphRAG framework by defining its key components, including query processor, retriever, organizer, generator, and data source. Furthermore, recognizing that graphs in different domains exhibit distinct relational patterns and require dedicated designs, we review GraphRAG techniques uniquely tailored to each domain. Finally, we discuss research challenges and brainstorm directions to inspire cross-disciplinary opportunities. Our survey repository is publicly maintained at https://github.com/Graph-RAG/GraphRAG/.,
    publicationDate: 2024-12-31,
    authors: ['Haoyu Han', 'Yu Wang', 'Harry Shomer', 'Kai Guo', 'Jiayuan Ding', 'Yongjia Lei', 'M. Halappanavar', 'Ryan Rossi', 'Subhabrata Mukherjee', 'Xianfeng Tang', 'Qianru He', 'Zhigang Hua', 'Bo Long', 'Tong Zhao', 'Neil Shah', 'Amin Javari', 'Yinglong Xia', 'Jiliang Tang'],
    score: 80.39720770839918
},
{
    title: Enhancing Structured-Data Retrieval with GraphRAG: Soccer Data Case Study,
    abstract: Extracting meaningful insights from large and complex datasets poses significant challenges, particularly in ensuring the accuracy and relevance of retrieved information. Traditional data retrieval methods such as sequential search and index-based retrieval often fail when handling intricate and interconnected data structures, resulting in incomplete or misleading outputs. To overcome these limitations, we introduce Structured-GraphRAG, a versatile framework designed to enhance information retrieval across structured datasets in natural language queries. Structured-GraphRAG utilizes multiple knowledge graphs, which represent data in a structured format and capture complex relationships between entities, enabling a more nuanced and comprehensive retrieval of information. This graph-based approach reduces the risk of errors in language model outputs by grounding responses in a structured format, thereby enhancing the reliability of results. We demonstrate the effectiveness of Structured-GraphRAG by comparing its performance with that of a recently published method using traditional retrieval-augmented generation. Our findings show that Structured-GraphRAG significantly improves query processing efficiency and reduces response times. While our case study focuses on soccer data, the framework's design is broadly applicable, offering a powerful tool for data analysis and enhancing language model applications across various structured domains.,
    publicationDate: 2024-09-26,
    authors: ['Zahra Sepasdar', 'Sushant Gautam', 'Cise Midoglu', 'M. Riegler', 'Paal Halvorsen'],
    score: 80.39720770839918
},
{
    title: Equipping Large Language Models with Memories: A GraphRAG Based Approach,
    abstract: Large language models (LLMs) have demonstrated strong capabilities in natural language understanding and generation, but they lack mechanisms to effectively store and retrieve information from past interactions. This problem hinders their potential for building truly conversational applications. To address this problem, we propose an approach to integrating memory into LLMs using GraphRAG, which is a framework that leverages Knowledge Graph and Retrieval Augmented Generation techniques for retrieving historical interactions. By representing the key knowledge contained in the dialogue history as a knowledge graph, we can capture complex relationships between entities and concepts mentioned in previous turns. We also introduce a mechanism for effectively accessing relevant nodes with the current query, allowing for more focused and efficient recall of past interactions. We evaluate our approach on benchmark datasets for question answering, text summarization, and dialogue systems, demonstrating significant improvements in performance compared to baseline LLMs. Our findings highlight the potential of GraphRAG as a powerful tool for equipping LLMs with robust memory capabilities, paving the way for more sophisticated and context-aware AI applications,
    publicationDate: 2024-10-06,
    authors: ['Tie Li'],
    score: 76
},
{
    title: Tokenvizz: GraphRAG-Inspired Tokenization Tool for Genomic Data Discovery and Visualization,
    abstract: Summary One of the primary challenges in biomedical research is the interpretation of complex genomic relationships and the prediction of functional interactions across the genome. Tokenvizz is a novel tool for genomic analysis that enhances data discovery and visualization by combining GraphRAG-inspired tokenization with graph-based modeling. In Tokenvizz, genomic sequences are represented as graphs, where sequence k-mers (tokens) serve as nodes and attention scores as edge weights, enabling researchers to visually interpret complex, non-linear relationships within DNA sequences. Through a web-based visualization interface, researchers can interactively explore these genomic relationships and extract biologically meaningful insights about regulatory patterns and functional elements. Applied to promoter-enhancer interaction prediction tasks, Tokenvizz outperformed traditional sequential models while providing interpretable insights into genomic features, demonstrating the advantage of graph-based representations for biological discovery. Availability and Implementation Tokenvizz, along with its user guide, is freely accessible on GitHub at: https://github.com/ceragoguztuzun/tokenvizz. ACM Reference Format Çerağ Oğuztüzün, Zhenxiang Gao, and Rong Xu. 2024. Tokenvizz: GraphRAG Inspired Tokenization Tool for Genomic Data Discovery and Visualization. In Proceedings of (Bioinformatics). ACM, New York, NY, USA, 7 pages. https://doi.org/XXXXXXX.XXXXXXX,
    publicationDate: 2024-12-06,
    authors: ['Çerağ Oğuztüzün', 'Zhenxiang Gao', 'Rong Xu'],
    score: 70
},
{
    title: LEGO-GraphRAG: Modularizing Graph-based Retrieval-Augmented Generation for Design Space Exploration,
    abstract: GraphRAG integrates (knowledge) graphs with large language models (LLMs) to improve reasoning accuracy and contextual relevance. Despite its promising applications and strong relevance to multiple research communities, such as databases and natural language processing, GraphRAG currently lacks modular workflow analysis, systematic solution frameworks, and insightful empirical studies. To bridge these gaps, we propose LEGO-GraphRAG, a modular framework that enables: 1) fine-grained decomposition of the GraphRAG workflow, 2) systematic classification of existing techniques and implemented GraphRAG instances, and 3) creation of new GraphRAG instances. Our framework facilitates comprehensive empirical studies of GraphRAG on large-scale real-world graphs and diverse query sets, revealing insights into balancing reasoning quality, runtime efficiency, and token or GPU cost, that are essential for building advanced GraphRAG systems.,
    publicationDate: 2024-11-06,
    authors: ['Yukun Cao', 'Zengyi Gao', 'Zhiyang Li', 'Xike Xie', 'S. K. Zhou'],
    score: 70
},
{
    title: Myanmar Law Cases and Proceedings Retrieval with GraphRAG,
    abstract: Legal document retrieval poses various challenges due to diverse linguistic and domain-specific complexities. The GraphRAG approach represents a significant advance in retrieving and summarizing archival case documents. It deals with the difficulties of accessing relevant legal information with inherent complexities. Further, it improves the efficiency of information retrieval by using graphical representations of legal texts. It enables lawyers to navigate the complex relationships between cases, statutes, and legal principles. The framework facilitates extracting relevant information and incorporates advanced natural language processing techniques for efficient summarization. It enables users to understand key legal concepts quickly. By fostering interdisciplinary collaboration and focusing on user-centered design, GraphRAG can significantly improve access to legal information, thereby meeting the growing needs of the legal community. This paper proposes a graph-rag-based approach for multilingual legal information retrieval (ML2IR), focusing on the Burmese language. Our graph-rag-based approach addresses the hallucination problem, crucial in legal information retrieval. Additionally, our work identifies important nodes and establishes contextual relationships, leading to higher accuracy and effective information retrieval.,
    publicationDate: 2024-12-15,
    authors: ['Shoon Lei Phyu', 'Shuhayel Jaman', 'Murataly Uchkempirov', 'Parag Kulkarni'],
    score: 70
},
{
    title: Enhancing Startup Success Predictions in Venture Capital: A GraphRAG Augmented Multivariate Time Series Method,
    abstract: In the Venture Capital (VC) industry, predicting the success of startups is challenging due to limited financial data and the need for subjective revenue forecasts. Previous methods based on time series analysis often fall short as they fail to incorporate crucial inter-company relationships such as competition and collaboration. To fill the gap, this paper aims to introduce a novel approach using GraphRAG augmented time series model. With GraphRAG, time series predictive methods are enhanced by integrating these vital relationships into the analysis framework, allowing for a more dynamic understanding of the startup ecosystem in venture capital. Our experimental results demonstrate that our model significantly outperforms previous models in startup success predictions.,
    publicationDate: 2024-08-18,
    authors: ['Zitian Gao', 'Yihao Xiao'],
    score: 70
},
{
    title: Mixture-of-PageRanks: Replacing Long-Context with Real-Time, Sparse GraphRAG,
    abstract: Recent advances have extended the context window of frontier LLMs dramatically, from a few thousand tokens up to millions, enabling entire books and codebases to fit into context. However, the compute costs of inferencing long-context LLMs are massive and often prohibitive in practice. RAG offers an efficient and effective alternative: retrieve and process only the subset of the context most important for the current task. Although promising, recent work applying RAG to long-context tasks has two core limitations: 1) there has been little focus on making the RAG pipeline compute efficient, and 2) such works only test on simple QA tasks, and their performance on more challenging tasks is unclear. To address this, we develop an algorithm based on PageRank, a graph-based retrieval algorithm, which we call mixture-of-PageRanks (MixPR). MixPR uses a mixture of PageRank-based graph-retrieval algorithms implemented using sparse matrices for efficent, cheap retrieval that can deal with a variety of complex tasks. Our MixPR retriever achieves state-of-the-art results across a wide range of long-context benchmark tasks, outperforming both existing RAG methods, specialized retrieval architectures, and long-context LLMs despite being far more compute efficient. Due to using sparse embeddings, our retriever is extremely compute efficient, capable of embedding and retrieving millions of tokens within a few seconds and runs entirely on CPU.,
    publicationDate: 2024-12-08,
    authors: ['Nick Alonso', 'Beren Millidge'],
    score: 70
},
{
    title: GraphRAG under Fire,
    abstract: GraphRAG advances retrieval-augmented generation (RAG) by structuring external knowledge as multi-scale knowledge graphs, enabling language models to integrate both broad context and granular details in their reasoning. While GraphRAG has demonstrated success across domains, its security implications remain largely unexplored. To bridge this gap, this work examines GraphRAG's vulnerability to poisoning attacks, uncovering an intriguing security paradox: compared to conventional RAG, GraphRAG's graph-based indexing and retrieval enhance resilience against simple poisoning attacks; meanwhile, the same features also create new attack surfaces. We present GRAGPoison, a novel attack that exploits shared relations in the knowledge graph to craft poisoning text capable of compromising multiple queries simultaneously. GRAGPoison employs three key strategies: i) relation injection to introduce false knowledge, ii) relation enhancement to amplify poisoning influence, and iii) narrative generation to embed malicious content within coherent text. Empirical evaluation across diverse datasets and models shows that GRAGPoison substantially outperforms existing attacks in terms of effectiveness (up to 98% success rate) and scalability (using less than 68% poisoning text). We also explore potential defensive measures and their limitations, identifying promising directions for future research.,
    publicationDate: 2025-01-23,
    authors: ['Jiacheng Liang', 'Yuhui Wang', 'Changjiang Li', 'Rongyi Zhu', 'Tanqiu Jiang', 'Neil Gong', 'Ting Wang'],
    score: 70
},
{
    title: A Survey of Graph Retrieval-Augmented Generation for Customized Large Language Models,
    abstract: Large language models (LLMs) have demonstrated remarkable capabilities in a wide range of tasks, yet their application to specialized domains remains challenging due to the need for deep expertise. Retrieval-augmented generation (RAG) has emerged as a promising solution to customize LLMs for professional fields by seamlessly integrating external knowledge bases, enabling real-time access to domain-specific expertise during inference. Despite its potential, traditional RAG systems, based on flat text retrieval, face three critical challenges: (i) complex query understanding in professional contexts, (ii) difficulties in knowledge integration across distributed sources, and (iii) system efficiency bottlenecks at scale. This survey presents a systematic analysis of Graph-based Retrieval-Augmented Generation (GraphRAG), a new paradigm that revolutionizes domain-specific LLM applications. GraphRAG addresses traditional RAG limitations through three key innovations: (i) graph-structured knowledge representation that explicitly captures entity relationships and domain hierarchies, (ii) efficient graph-based retrieval techniques that enable context-preserving knowledge retrieval with multihop reasoning ability, and (iii) structure-aware knowledge integration algorithms that leverage retrieved knowledge for accurate and logical coherent generation of LLMs. In this survey, we systematically analyze the technical foundations of GraphRAG and examine current implementations across various professional domains, identifying key technical challenges and promising research directions. All the related resources of GraphRAG, including research papers, open-source data, and projects, are collected for the community in \textcolor{blue}{\url{https://github.com/DEEP-PolyU/Awesome-GraphRAG}}.,
    publicationDate: 2025-01-21,
    authors: ['Qinggang Zhang', 'Shengyuan Chen', 'Yuan-Qi Bei', 'Zheng Yuan', 'Huachi Zhou', 'Zijin Hong', 'Junnan Dong', 'Hao Chen', 'Yi Chang', 'Xiao Huang'],
    score: 70
},
{
    title: FastRAG: Retrieval Augmented Generation for Semi-structured Data,
    abstract: Efficiently processing and interpreting network data is critical for the operation of increasingly complex networks. Recent advances in Large Language Models (LLM) and Retrieval-Augmented Generation (RAG) techniques have improved data processing in network management. However, existing RAG methods like VectorRAG and GraphRAG struggle with the complexity and implicit nature of semi-structured technical data, leading to inefficiencies in time, cost, and retrieval. This paper introduces FastRAG, a novel RAG approach designed for semi-structured data. FastRAG employs schema learning and script learning to extract and structure data without needing to submit entire data sources to an LLM. It integrates text search with knowledge graph (KG) querying to improve accuracy in retrieving context-rich information. Evaluation results demonstrate that FastRAG provides accurate question answering, while improving up to 90% in time and 85% in cost compared to GraphRAG.,
    publicationDate: 2024-11-21,
    authors: ['Amar Abane', 'Anis Bekri', 'Abdella Battou'],
    score: 70
},
{
    title: Generating Knowledge Graphs from Large Language Models: A Comparative Study of GPT-4, LLaMA 2, and BERT,
    abstract: Knowledge Graphs (KGs) are essential for the functionality of GraphRAGs, a form of Retrieval-Augmented Generative Systems (RAGs) that excel in tasks requiring structured reasoning and semantic understanding. However, creating KGs for GraphRAGs remains a significant challenge due to accuracy and scalability limitations of traditional methods. This paper introduces a novel approach leveraging large language models (LLMs) like GPT-4, LLaMA 2 (13B), and BERT to generate KGs directly from unstructured data, bypassing traditional pipelines. Using metrics such as Precision, Recall, F1-Score, Graph Edit Distance, and Semantic Similarity, we evaluate the models' ability to generate high-quality KGs. Results demonstrate that GPT-4 achieves superior semantic fidelity and structural accuracy, LLaMA 2 excels in lightweight, domain-specific graphs, and BERT provides insights into challenges in entity-relationship modeling. This study underscores the potential of LLMs to streamline KG creation and enhance GraphRAG accessibility for real-world applications, while setting a foundation for future advancements.,
    publicationDate: 2024-12-10,
    authors: ['Ahan Bhatt', 'Nandan Vaghela', 'Kush Dudhia'],
    score: 70
},
{
    title: Development of an Intelligent Coal Production and Operation Platform Based on a Real-Time Data Warehouse and AI Model,
    abstract: Smart mining solutions currently suffer from inadequate big data support and insufficient AI applications. The main reason for these limitations is the absence of a comprehensive industrial internet cloud platform tailored for the coal industry, which restricts resource integration. This paper presents the development of an innovative platform designed to enhance safety, operational efficiency, and automation in fully mechanized coal mining in China. This platform integrates cloud edge computing, real-time data processing, and AI-driven analytics to improve decision-making and maintenance strategies. Several AI models have been developed for the proactive maintenance of comprehensive mining face equipment, including early warnings for periodic weighting and the detection of common faults such as those in the shearer, hydraulic support, and conveyor. The platform leverages large-scale knowledge graph models and Graph Retrieval-Augmented Generation (GraphRAG) technology to build structured knowledge graphs. This facilitates intelligent Q&A capabilities and precise fault diagnosis, thereby enhancing system responsiveness and improving the accuracy of fault resolution. The practical process of implementing such a platform primarily based on open-source components is summarized in this paper.,
    publicationDate: 2024-10-19,
    authors: ['Yongtao Wang', 'Yinhui Feng', 'Chengfeng Xi', 'Bochao Wang', 'Bo Tang', 'Yanzhao Geng'],
    score: 70
},
{
    title: CypherBench: Towards Precise Retrieval over Full-scale Modern Knowledge Graphs in the LLM Era,
    abstract: Retrieval from graph data is crucial for augmenting large language models (LLM) with both open-domain knowledge and private enterprise data, and it is also a key component in the recent GraphRAG system (edge et al., 2024). Despite decades of research on knowledge graphs and knowledge base question answering, leading LLM frameworks (e.g. Langchain and LlamaIndex) have only minimal support for retrieval from modern encyclopedic knowledge graphs like Wikidata. In this paper, we analyze the root cause and suggest that modern RDF knowledge graphs (e.g. Wikidata, Freebase) are less efficient for LLMs due to overly large schemas that far exceed the typical LLM context window, use of resource identifiers, overlapping relation types and lack of normalization. As a solution, we propose property graph views on top of the underlying RDF graph that can be efficiently queried by LLMs using Cypher. We instantiated this idea on Wikidata and introduced CypherBench, the first benchmark with 11 large-scale, multi-domain property graphs with 7.8 million entities and over 10,000 questions. To achieve this, we tackled several key challenges, including developing an RDF-to-property graph conversion engine, creating a systematic pipeline for text-to-Cypher task generation, and designing new evaluation metrics.,
    publicationDate: 2024-12-24,
    authors: ['Yanlin Feng', 'Simone Papicchio', 'Sajjadur Rahman'],
    score: 70
},
{
    title: Can LLMs be Good Graph Judger for Knowledge Graph Construction?,
    abstract: In real-world scenarios, most of the data obtained from information retrieval (IR) system is unstructured. Converting natural language sentences into structured Knowledge Graphs (KGs) remains a critical challenge. The quality of constructed KGs may also impact the performance of some KG-dependent domains like GraphRAG systems and recommendation systems. Recently, Large Language Models (LLMs) have demonstrated impressive capabilities in addressing a wide range of natural language processing tasks. However, there are still challenges when utilizing LLMs to address the task of generating structured KGs. And we have identified three limitations with respect to existing KG construction methods. (1)There is a large amount of information and excessive noise in real-world documents, which could result in extracting messy information. (2)Native LLMs struggle to effectively extract accuracy knowledge from some domain-specific documents. (3)Hallucinations phenomenon cannot be overlooked when utilizing LLMs directly as an unsupervised method for constructing KGs. In this paper, we propose GraphJudger, a knowledge graph construction framework to address the aforementioned challenges. We introduce three innovative modules in our method, which are entity-centric iterative text denoising, knowledge aware instruction tuning and graph judgement, respectively. We seek to utilize the capacity of LLMs to function as a graph judger, a capability superior to their role only as a predictor for KG construction problems. Experiments conducted on two general text-graph pair datasets and one domain-specific text-graph pair dataset show superior performances compared to baseline methods. The code of our proposed method is available at https://github.com/hhy-huang/GraphJudger.,
    publicationDate: 2024-11-26,
    authors: ['Haoyu Huang', 'Chong Chen', 'Conghui He', 'Yang Li', 'Jiawei Jiang', 'Wentao Zhang'],
    score: 70
},
{
    title: When Graph Meets Retrieval Augmented Generation for Wireless Networks: A Tutorial and Case Study,
    abstract: The rapid development of next-generation networking technologies underscores their transformative role in revolutionizing modern communication systems, enabling faster, more reliable, and highly interconnected solutions. However, such development has also brought challenges to network optimizations. Thanks to the emergence of Large Language Models (LLMs) in recent years, tools including Retrieval Augmented Generation (RAG) have been developed and applied in various fields including networking, and have shown their effectiveness. Taking one step further, the integration of knowledge graphs into RAG frameworks further enhanced the performance of RAG in networking applications such as Intent-Driven Networks (IDNs) and spectrum knowledge maps by providing more contextually relevant responses through more accurate retrieval of related network information. This paper introduces the RAG framework that integrates knowledge graphs in its database and explores such framework's application in networking. We begin by exploring RAG's applications in networking and the limitations of conventional RAG and present the advantages that knowledge graphs' structured knowledge representation brings to the retrieval and generation processes. Next, we propose a detailed GraphRAG-based framework for networking, including a step-by-step tutorial on its construction. Our evaluation through a case study on channel gain prediction demonstrates GraphRAG's enhanced capability in generating accurate, contextually rich responses, surpassing traditional RAG models. Finally, we discuss key future directions for applying knowledge-graphs-empowered RAG frameworks in networking, including robust updates, mitigation of hallucination, and enhanced security measures for networking applications.,
    publicationDate: 2024-12-10,
    authors: ['Yang Xiong', 'Ruichen Zhang', 'Yinqiu Liu', 'D. Niyato', 'Zehui Xiong', 'Ying-Chang Liang', 'Shiwen Mao'],
    score: 70
},
{
    title: Soccer-GraphRAG: Applications of GraphRAG in Soccer,
    abstract: None,
    publicationDate: 2024-01-01,
    authors: ['Zahra Sepasdar', 'Sushant Gautam', 'Cise Midoglu', 'M. Riegler', 'Pål Halvorsen'],
    score: 66.47918433002164
},
{
    title: Speech Recognition Method Based on GraphRAG,
    abstract: None,
    publicationDate: 2024-12-01,
    authors: ['Wei Zhao', 'Rongsheng Zhao'],
    score: 60
},
{
    title: Hybrid large language model approach for prompt and sensitive defect management: A comparative analysis of hybrid, non-hybrid, and GraphRAG approaches,
    abstract: None,
    publicationDate: 2025-03-01,
    authors: ['Kahyun Jeon', 'Ghang Lee'],
    score: 50
},
{
    title: LEGO-GraphRAG: Modularizing Graph-based Retrieval-Augmented Generation for Design Space Exploration [Preliminary Version],
    abstract: GraphRAG addresses significant challenges in Retrieval-Augmented Generation (RAG) by leveraging graphs with embedded knowledge to enhance the reasoning capabilities of Large Language Models (LLMs). Despite its promising potential, the GraphRAG community currently lacks a unified framework for fine-grained decomposition of the graph-based knowledge retrieval process. Furthermore, there is no systematic categorization or evaluation of existing solutions within the retrieval process. In this paper, we present LEGO-GraphRAG , a modular framework that decomposes the retrieval process of GraphRAG into three interconnected modules: subgraph-extraction , path-filtering , and path-refinement . We systematically summarize and classify the algorithms and neural network (NN) models relevant to each module, providing a clearer understanding of the design space for GraphRAG instances. Additionally, we identify key design factors, such as Graph Coupling and Computational Cost , that influence the effectiveness of GraphRAG implementations. Through extensive empirical studies, we construct high-quality GraphRAG instances using a representative selection of solutions and analyze their impact on retrieval and reasoning performance. Our findings offer critical insights into optimizing GraphRAG instance design, ultimately contributing to the advancement of more accurate and contextually relevant LLM applications.,
    publicationDate: None,
    authors: ['Yukun Cao', 'Zengyi Gao', 'Zhiyang Li', '†. XikeXie', 'S. K. Zhou', 'S. Kevin', 'LEGO-GraphRAG', 'Kevin Zhou'],
    score: 50
},
{
    title: GRAFT: Graph Retrieval Augmented Fine Tuning for Multi-Hop Query Summarization,
    abstract: Traditional retrieval-augmented generation (RAG) approaches struggle with multi-hop reasoning and global query-focused summarization tasks over large document corpora, which require summarizing broad themes and contexts and a holistic knowledge of documents. We propose GRAFT (Graph Retrieval Augmented Fine-Tuning), a novel approach that combines the strengths of the Retrieval Augmented Fine-Tuning (RAFT) methodology and the GraphRAG technique. GRAFT fine-tunes large language models (LLMs) on a simulated imperfect retrieval setting, training the model to identify relevant documents and ignore distractors in the provided context. The model is then coupled with graphRAG at inference. To investigate the effectiveness of the GRAFT methodology, we constructed a knowledge graph using 74 Wikipedia source documents and extracted communities within this graph. We then summarized these communities, leveraging local and global relationships between documents for retrieval, fine-tuned a Microsoft Phi-2 model using the RAFT approach on a subset of the HotPotQA dataset, and evaluated its performance on a custom set of multi-hop and global questions generated from Wikipedia articles published in 2024. Our experimental results demonstrate that GRAFT outperforms baseline models, including the Baseline RAG model, the RAFT model, and the Baseline GraphRAG model, across various evaluation metrics like BERT, BLEU, ROUGE-1, and Semantic Similarity. In particular, GRAFT achieves the highest scores on global questions, showcasing its effectiveness in query-focused summarization tasks that require understanding broad themes and contexts over large document corpora.,
    publicationDate: None,
    authors: ['Sonya Jin', 'Sunny Yu', 'Natalia Kokoromyti'],
    score: 50
},
