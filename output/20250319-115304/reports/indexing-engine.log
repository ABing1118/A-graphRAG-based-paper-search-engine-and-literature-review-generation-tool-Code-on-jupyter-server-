11:53:04,60 graphrag.config.read_dotenv INFO Loading pipeline .env file
11:53:04,66 graphrag.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 6",
        "type": "openai_chat",
        "model": "qwen2:latest",
        "max_tokens": 2000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 180.0,
        "api_base": "http://localhost:11434/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./",
    "reporting": {
        "type": "file",
        "base_dir": "inputs/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "inputs/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 6",
            "type": "openai_embedding",
            "model": "nomic-embed-text:latest",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 400,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 6",
            "type": "openai_chat",
            "model": "qwen2:latest",
            "max_tokens": 2000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "paper_title",
            "author",
            "publication_date",
            "abstract"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 6",
            "type": "openai_chat",
            "model": "qwen2:latest",
            "max_tokens": 2000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 6",
            "type": "openai_chat",
            "model": "qwen2:latest",
            "max_tokens": 2000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 6",
            "type": "openai_chat",
            "model": "qwen2:latest",
            "max_tokens": 2000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": true,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
11:53:04,67 graphrag.index.create_pipeline_config INFO skipping workflows 
11:53:04,72 graphrag.index.run INFO Running pipeline
11:53:04,72 graphrag.index.storage.file_pipeline_storage INFO Creating file storage at inputs/artifacts
11:53:04,73 graphrag.index.input.load_input INFO loading input from root_dir=input
11:53:04,73 graphrag.index.input.load_input INFO using file storage for input
11:53:04,73 graphrag.index.storage.file_pipeline_storage INFO search input for files matching .*\.txt$
11:53:04,74 graphrag.index.input.text INFO found text files from input, found [('papers.txt', {}), ('.ipynb_checkpoints/papers-checkpoint.txt', {})]
11:53:04,77 graphrag.index.input.text INFO Found 2 files, loading 2
11:53:04,78 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_final_covariates', 'create_summarized_entities', 'join_text_units_to_covariate_ids', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents']
11:53:04,79 graphrag.index.run INFO Final # of rows loaded: 2
11:53:04,325 graphrag.index.run INFO Running workflow: create_base_text_units...
11:53:04,326 graphrag.index.run INFO dependencies for create_base_text_units: []
11:53:04,326 datashaper.workflow.workflow INFO executing verb orderby
11:53:04,328 datashaper.workflow.workflow INFO executing verb zip
11:53:04,329 datashaper.workflow.workflow INFO executing verb aggregate_override
11:53:04,332 datashaper.workflow.workflow INFO executing verb chunk
11:53:04,584 datashaper.workflow.workflow INFO executing verb select
11:53:04,585 datashaper.workflow.workflow INFO executing verb unroll
11:53:04,587 datashaper.workflow.workflow INFO executing verb rename
11:53:04,587 datashaper.workflow.workflow INFO executing verb genid
11:53:04,595 datashaper.workflow.workflow INFO executing verb unzip
11:53:04,596 datashaper.workflow.workflow INFO executing verb copy
11:53:04,596 datashaper.workflow.workflow INFO executing verb filter
11:53:04,601 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_text_units.parquet
11:53:04,842 graphrag.index.run INFO Running workflow: create_base_extracted_entities...
11:53:04,842 graphrag.index.run INFO dependencies for create_base_extracted_entities: ['create_base_text_units']
11:53:04,843 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
11:53:04,848 datashaper.workflow.workflow INFO executing verb entity_extract
11:53:04,857 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=http://localhost:11434/v1
11:53:04,883 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for qwen2:latest: TPM=0, RPM=0
11:53:04,883 graphrag.index.llm.load_llm INFO create concurrency limiter for qwen2:latest: 25
11:53:11,901 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:53:11,906 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.918999999994412. input_tokens=2690, output_tokens=153
11:53:14,622 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:53:14,623 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 9.625. input_tokens=2690, output_tokens=242
11:53:17,172 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:53:17,173 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 12.181999999796972. input_tokens=2690, output_tokens=136
11:53:19,349 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:53:19,350 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 14.393000000156462. input_tokens=2691, output_tokens=397
11:53:20,175 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:53:20,176 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 15.18099999986589. input_tokens=2690, output_tokens=50
11:53:20,401 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:53:20,402 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 15.452999999979511. input_tokens=2690, output_tokens=406
11:53:22,153 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:53:22,154 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 17.231000000145286. input_tokens=2689, output_tokens=27
11:53:25,177 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:53:25,178 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 20.250999999931082. input_tokens=2688, output_tokens=111
11:53:29,6 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:53:29,7 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 24.003000000026077. input_tokens=2690, output_tokens=389
11:53:30,576 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:53:30,577 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 25.631999999983236. input_tokens=2689, output_tokens=255
11:53:31,527 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:53:31,529 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 26.597999999998137. input_tokens=2689, output_tokens=177
11:53:34,577 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:53:34,578 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 29.61699999985285. input_tokens=2690, output_tokens=395
11:53:36,123 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:53:36,125 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 31.14199999999255. input_tokens=2690, output_tokens=117
11:53:39,581 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:53:39,582 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 34.56999999983236. input_tokens=2690, output_tokens=132
11:53:41,484 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:53:41,485 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 36.5679999999702. input_tokens=2690, output_tokens=348
11:53:41,850 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:53:41,851 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 36.881000000052154. input_tokens=2690, output_tokens=286
11:53:49,656 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:53:49,657 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 44.7160000000149. input_tokens=2690, output_tokens=436
11:53:51,277 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:53:51,278 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 46.37099999981001. input_tokens=2688, output_tokens=290
11:53:51,302 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:53:51,303 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 46.33700000005774. input_tokens=2690, output_tokens=302
11:53:55,826 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:53:55,828 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 50.87400000006892. input_tokens=2690, output_tokens=464
11:54:00,533 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:54:00,534 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 55.5570000000298. input_tokens=2690, output_tokens=295
11:54:01,501 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:54:01,503 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 56.56499999994412. input_tokens=2691, output_tokens=287
11:54:02,402 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:54:02,403 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 57.48999999999069. input_tokens=2690, output_tokens=298
11:54:05,330 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:54:05,331 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 50.70699999993667. input_tokens=2690, output_tokens=67
11:54:07,579 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:54:07,581 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 62.57199999992736. input_tokens=2689, output_tokens=339
11:54:10,500 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:54:10,501 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 65.40399999986403. input_tokens=2690, output_tokens=226
11:54:11,831 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:54:11,832 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 52.48200000007637. input_tokens=2690, output_tokens=113
11:54:12,639 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:54:12,640 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 60.73400000017136. input_tokens=2691, output_tokens=283
11:54:14,858 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:54:14,859 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 57.68199999979697. input_tokens=2689, output_tokens=242
11:54:17,72 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:54:17,73 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 56.670000000158325. input_tokens=2690, output_tokens=125
11:54:18,23 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:54:18,24 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 57.84900000016205. input_tokens=2690, output_tokens=167
11:54:24,15 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:54:24,16 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 55.00799999991432. input_tokens=2690, output_tokens=222
11:54:26,733 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:54:26,734 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 61.55599999986589. input_tokens=2690, output_tokens=383
11:54:29,849 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:54:29,850 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 59.27200000011362. input_tokens=2690, output_tokens=394
11:54:33,229 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:54:33,231 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 57.105000000214204. input_tokens=2690, output_tokens=82
11:54:38,521 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:54:38,522 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 66.99300000001676. input_tokens=2691, output_tokens=445
11:54:39,847 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:54:39,849 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 65.26699999999255. input_tokens=2690, output_tokens=398
11:54:42,457 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:54:42,459 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 60.60700000007637. input_tokens=2690, output_tokens=47
11:54:46,769 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:54:46,770 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 67.18699999991804. input_tokens=2690, output_tokens=417
11:54:47,995 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:54:47,996 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 58.337999999988824. input_tokens=2689, output_tokens=141
11:54:58,775 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:54:58,777 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 67.497999999905. input_tokens=2690, output_tokens=403
11:54:58,848 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:54:58,849 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 67.5449999999255. input_tokens=2690, output_tokens=404
11:55:03,740 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:55:03,741 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 63.20600000000559. input_tokens=2690, output_tokens=133
11:55:04,727 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:55:04,729 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 102.57300000009127. input_tokens=2690, output_tokens=1660
11:55:07,319 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:55:07,321 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 65.8179999999702. input_tokens=2691, output_tokens=62
11:55:09,725 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:55:09,726 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 67.32000000006519. input_tokens=2690, output_tokens=125
11:55:13,195 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:55:13,197 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 77.36800000001676. input_tokens=2690, output_tokens=403
11:55:17,851 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:55:17,853 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 70.27200000011362. input_tokens=2690, output_tokens=275
11:55:21,51 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:55:21,52 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 70.55000000004657. input_tokens=34, output_tokens=294
11:55:22,451 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:55:22,452 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 69.80799999996088. input_tokens=34, output_tokens=51
11:55:26,843 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:55:26,844 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 71.98399999993853. input_tokens=34, output_tokens=169
11:55:27,698 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:55:27,700 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 75.86699999985285. input_tokens=34, output_tokens=374
11:55:35,28 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:55:35,29 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 77.00100000016391. input_tokens=34, output_tokens=278
11:55:35,431 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:55:35,432 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 78.35800000000745. input_tokens=34, output_tokens=316
11:55:36,660 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:55:36,662 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 115.17599999997765. input_tokens=2690, output_tokens=1813
11:55:39,248 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:55:39,249 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 75.23200000007637. input_tokens=34, output_tokens=155
11:55:40,731 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:55:40,733 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 67.50099999993108. input_tokens=34, output_tokens=53
11:55:43,373 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:55:43,374 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 64.85100000002421. input_tokens=34, output_tokens=100
11:55:45,497 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:55:45,499 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 78.76399999996647. input_tokens=34, output_tokens=360
11:55:46,231 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:55:46,232 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 76.38100000005215. input_tokens=34, output_tokens=358
11:55:50,331 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:55:50,332 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 67.87199999997392. input_tokens=34, output_tokens=174
11:55:52,988 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:55:52,989 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 66.2180000001099. input_tokens=34, output_tokens=254
11:55:56,723 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:55:56,725 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 68.72800000011921. input_tokens=34, output_tokens=274
11:55:57,286 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:55:57,287 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 58.51000000000931. input_tokens=34, output_tokens=190
11:55:58,53 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:55:58,54 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 78.2050000000745. input_tokens=34, output_tokens=575
11:55:59,253 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:55:59,257 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 113.9230000001844. input_tokens=2691, output_tokens=1899
11:56:01,345 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:01,346 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 56.6160000001546. input_tokens=34, output_tokens=120
11:56:02,588 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:02,589 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 58.847000000067055. input_tokens=34, output_tokens=198
11:56:02,850 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:02,851 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 55.52899999986403. input_tokens=34, output_tokens=131
11:56:04,396 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:04,397 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 65.54700000002049. input_tokens=34, output_tokens=288
11:56:08,427 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:08,428 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 47.375. input_tokens=34, output_tokens=176
11:56:09,587 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:09,588 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 56.39099999982864. input_tokens=34, output_tokens=261
11:56:12,253 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:12,254 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 54.39999999990687. input_tokens=34, output_tokens=379
11:56:14,7 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:14,8 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 64.28100000019185. input_tokens=34, output_tokens=498
11:56:14,313 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:14,314 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 51.86100000003353. input_tokens=34, output_tokens=252
11:56:14,621 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:14,622 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 47.77700000000186. input_tokens=34, output_tokens=212
11:56:18,247 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:18,248 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 41.58600000012666. input_tokens=34, output_tokens=168
11:56:20,485 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:20,486 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 45.054000000003725. input_tokens=34, output_tokens=270
11:56:22,996 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:22,998 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 47.968000000109896. input_tokens=34, output_tokens=406
11:56:23,398 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:23,399 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 44.148999999975786. input_tokens=34, output_tokens=232
11:56:24,459 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:24,460 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 56.76000000000931. input_tokens=34, output_tokens=544
11:56:25,244 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:25,245 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 39.74600000004284. input_tokens=34, output_tokens=76
11:56:26,217 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:26,221 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 39.98800000012852. input_tokens=34, output_tokens=71
11:56:28,63 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:28,64 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 44.68900000001304. input_tokens=34, output_tokens=212
11:56:29,457 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:29,458 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 48.72500000009313. input_tokens=34, output_tokens=381
11:56:30,880 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:30,881 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 40.54799999995157. input_tokens=34, output_tokens=237
11:56:30,896 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:30,897 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 34.17100000008941. input_tokens=34, output_tokens=126
11:56:32,299 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:32,301 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 39.311999999918044. input_tokens=34, output_tokens=252
11:56:33,830 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:33,831 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 34.57299999985844. input_tokens=34, output_tokens=121
11:56:34,23 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:34,24 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 32.67699999990873. input_tokens=34, output_tokens=70
11:56:37,43 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:37,44 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 39.756000000052154. input_tokens=34, output_tokens=298
11:56:37,340 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:37,341 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 39.286000000080094. input_tokens=34, output_tokens=233
11:56:42,321 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:42,322 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 39.47000000020489. input_tokens=34, output_tokens=341
11:56:43,136 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:43,137 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 34.70800000010058. input_tokens=34, output_tokens=237
11:56:43,448 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:43,449 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 39.05099999997765. input_tokens=34, output_tokens=271
11:56:43,976 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:43,978 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 41.38800000003539. input_tokens=34, output_tokens=402
11:56:45,7 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:45,8 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 35.41899999999441. input_tokens=34, output_tokens=60
11:56:47,902 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:47,903 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 33.587999999988824. input_tokens=2689, output_tokens=86
11:56:51,373 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:51,374 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 39.118999999947846. input_tokens=34, output_tokens=235
11:56:53,196 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:53,199 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 32.71200000005774. input_tokens=2689, output_tokens=39
11:56:53,260 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:53,261 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 39.251999999862164. input_tokens=2690, output_tokens=258
11:56:54,150 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:54,152 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 39.53000000002794. input_tokens=2689, output_tokens=253
11:56:57,520 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:56:57,521 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 34.5230000000447. input_tokens=2690, output_tokens=104
11:57:00,269 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:57:00,271 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 35.80999999982305. input_tokens=2690, output_tokens=190
11:57:01,405 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:57:01,406 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 43.156999999890104. input_tokens=2689, output_tokens=392
11:57:02,162 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:57:02,163 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 38.76299999980256. input_tokens=34, output_tokens=253
11:57:10,205 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:57:10,206 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 43.98399999993853. input_tokens=2690, output_tokens=298
11:57:11,268 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:57:11,270 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 46.023999999975786. input_tokens=2690, output_tokens=411
11:57:14,106 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:57:14,107 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 46.04300000006333. input_tokens=2691, output_tokens=386
11:57:15,103 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:57:15,104 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 45.64500000001863. input_tokens=2689, output_tokens=393
11:57:19,307 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:57:19,308 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 48.42299999995157. input_tokens=2690, output_tokens=241
11:57:24,152 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:57:24,153 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 53.25499999988824. input_tokens=2690, output_tokens=401
11:57:27,203 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:57:27,204 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 53.373000000137836. input_tokens=2690, output_tokens=421
11:57:28,103 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:57:28,104 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 55.80199999990873. input_tokens=2690, output_tokens=443
11:57:30,793 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:57:30,794 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 53.45299999997951. input_tokens=2690, output_tokens=78
11:57:32,13 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:57:32,14 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 49.6909999998752. input_tokens=2690, output_tokens=91
11:57:33,395 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:57:33,397 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 59.37199999997392. input_tokens=2690, output_tokens=431
11:57:35,674 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:57:35,675 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 52.53799999994226. input_tokens=2689, output_tokens=108
11:57:36,488 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:57:36,489 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 53.03900000010617. input_tokens=2690, output_tokens=85
11:57:38,762 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:57:38,763 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 61.71900000004098. input_tokens=34, output_tokens=441
11:57:41,587 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:57:41,588 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 56.57899999991059. input_tokens=2690, output_tokens=143
11:57:42,758 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:57:42,759 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 58.78000000002794. input_tokens=2688, output_tokens=234
11:57:46,48 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:57:46,49 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 52.85000000009313. input_tokens=2689, output_tokens=99
11:57:47,323 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:57:47,324 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 55.945999999996275. input_tokens=2689, output_tokens=236
11:57:50,159 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:57:50,160 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 62.256000000052154. input_tokens=2690, output_tokens=400
11:57:51,545 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:57:51,546 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 54.023999999975786. input_tokens=2690, output_tokens=120
11:57:54,201 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:57:54,202 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 60.93999999994412. input_tokens=2690, output_tokens=324
11:57:55,307 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:57:55,308 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 53.143999999854714. input_tokens=2691, output_tokens=12
11:58:00,71 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:58:00,72 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 65.92000000015832. input_tokens=2691, output_tokens=411
11:58:02,780 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:58:02,781 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 62.5089999998454. input_tokens=2690, output_tokens=372
11:58:04,628 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:58:04,629 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 63.221999999834225. input_tokens=2691, output_tokens=397
11:58:06,877 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:58:06,878 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 56.67100000008941. input_tokens=2690, output_tokens=363
11:58:09,450 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:58:09,451 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 54.34600000013597. input_tokens=2689, output_tokens=121
11:58:13,50 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:58:13,53 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 53.743999999947846. input_tokens=2691, output_tokens=194
11:58:14,652 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:58:14,654 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 63.38300000014715. input_tokens=2690, output_tokens=416
11:58:20,777 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:58:20,779 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 66.6699999999255. input_tokens=2690, output_tokens=555
11:58:22,175 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:58:22,176 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 58.02199999988079. input_tokens=2690, output_tokens=405
11:58:23,554 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:58:23,555 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 56.346999999834225. input_tokens=2691, output_tokens=313
11:58:25,874 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:58:25,876 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 57.77199999988079. input_tokens=2690, output_tokens=343
11:58:28,943 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:58:28,944 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 53.26800000015646. input_tokens=2690, output_tokens=82
11:58:31,647 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:58:31,648 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 60.85299999988638. input_tokens=2690, output_tokens=300
11:58:35,836 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:58:35,837 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 62.43999999994412. input_tokens=2690, output_tokens=389
11:58:36,582 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:58:36,584 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 64.56899999990128. input_tokens=2690, output_tokens=410
11:58:39,566 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:58:39,567 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 57.97799999988638. input_tokens=2690, output_tokens=79
11:58:39,740 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:58:39,741 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 63.25100000016391. input_tokens=2690, output_tokens=324
11:58:43,476 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:58:43,477 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 60.717999999877065. input_tokens=2690, output_tokens=219
11:58:44,186 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:58:44,187 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 65.4230000001844. input_tokens=2689, output_tokens=375
11:58:46,431 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:58:46,432 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 60.38299999991432. input_tokens=34, output_tokens=224
11:58:48,482 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:58:48,483 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 56.932999999960884. input_tokens=34, output_tokens=158
11:58:48,878 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:58:48,879 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 61.554000000003725. input_tokens=2689, output_tokens=291
11:58:49,601 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:58:49,602 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 59.4409999998752. input_tokens=34, output_tokens=229
11:58:54,585 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:58:54,586 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 59.278000000165775. input_tokens=34, output_tokens=251
11:58:55,267 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:58:55,269 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 61.06600000010803. input_tokens=34, output_tokens=346
11:58:55,535 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:58:55,536 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 55.462999999988824. input_tokens=34, output_tokens=258
11:58:57,857 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:58:57,858 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 55.075999999884516. input_tokens=34, output_tokens=323
11:59:01,12 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:01,13 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 54.13500000000931. input_tokens=34, output_tokens=204
11:59:02,149 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:02,150 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 49.09600000013597. input_tokens=34, output_tokens=169
11:59:03,602 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:03,603 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 58.97299999999814. input_tokens=2690, output_tokens=316
11:59:05,253 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:05,254 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 55.80199999990873. input_tokens=34, output_tokens=365
11:59:06,565 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:06,566 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 51.911000000080094. input_tokens=34, output_tokens=217
11:59:09,698 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:09,699 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 46.14199999999255. input_tokens=34, output_tokens=185
11:59:10,301 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:10,302 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 44.42600000021048. input_tokens=34, output_tokens=159
11:59:14,136 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:14,137 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 45.192000000039116. input_tokens=34, output_tokens=174
11:59:14,607 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:14,608 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 42.959000000031665. input_tokens=34, output_tokens=184
11:59:14,731 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:14,732 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 52.55499999993481. input_tokens=34, output_tokens=455
11:59:17,632 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:17,633 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 41.795000000158325. input_tokens=34, output_tokens=146
11:59:20,209 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:20,210 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 40.467999999877065. input_tokens=2690, output_tokens=67
11:59:20,974 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:20,976 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 60.19699999992736. input_tokens=34, output_tokens=748
11:59:20,998 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:20,999 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 41.4320000000298. input_tokens=34, output_tokens=231
11:59:25,185 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:25,186 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 40.997999999905005. input_tokens=34, output_tokens=189
11:59:25,192 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:25,194 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 48.610000000102445. input_tokens=34, output_tokens=412
11:59:25,766 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:25,767 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 42.28899999987334. input_tokens=34, output_tokens=239
11:59:27,251 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:27,252 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 38.37199999997392. input_tokens=34, output_tokens=82
11:59:27,552 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:27,553 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 41.12000000011176. input_tokens=34, output_tokens=275
11:59:30,975 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:30,976 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 41.372999999905005. input_tokens=34, output_tokens=231
11:59:31,362 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:31,363 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 36.093000000109896. input_tokens=34, output_tokens=168
11:59:31,521 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:31,522 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 43.03800000017509. input_tokens=34, output_tokens=259
11:59:31,877 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:31,878 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 37.290999999968335. input_tokens=34, output_tokens=192
11:59:33,203 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:33,204 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 32.19000000017695. input_tokens=34, output_tokens=63
11:59:34,167 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:34,168 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 36.3090000001248. input_tokens=34, output_tokens=105
11:59:35,16 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:35,19 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 39.48200000007637. input_tokens=34, output_tokens=156
11:59:35,679 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:35,680 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 32.075999999884516. input_tokens=34, output_tokens=100
11:59:36,349 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:36,350 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 34.19900000002235. input_tokens=34, output_tokens=172
11:59:37,300 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:37,301 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 32.045999999856576. input_tokens=34, output_tokens=122
11:59:41,33 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:41,34 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 26.89700000011362. input_tokens=34, output_tokens=163
11:59:41,253 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:41,254 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 34.686999999918044. input_tokens=34, output_tokens=239
11:59:41,485 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:41,486 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 31.786000000080094. input_tokens=34, output_tokens=220
11:59:42,141 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:42,142 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 31.838999999919906. input_tokens=34, output_tokens=228
11:59:45,980 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:45,981 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 31.372000000206754. input_tokens=34, output_tokens=199
11:59:46,333 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:46,334 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 26.122999999905005. input_tokens=34, output_tokens=183
11:59:48,921 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:48,924 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 34.186999999918044. input_tokens=34, output_tokens=314
11:59:49,353 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:49,354 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 28.377000000094995. input_tokens=34, output_tokens=138
11:59:51,38 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:51,40 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 33.40599999995902. input_tokens=34, output_tokens=399
11:59:51,906 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:51,908 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 30.908000000054017. input_tokens=34, output_tokens=228
11:59:54,209 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:54,210 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 28.441999999806285. input_tokens=34, output_tokens=104
11:59:59,451 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:59,452 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 31.898999999975786. input_tokens=2690, output_tokens=181
11:59:59,676 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:59,677 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 34.48999999999069. input_tokens=34, output_tokens=385
11:59:59,700 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
11:59:59,701 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 34.506000000052154. input_tokens=34, output_tokens=371
12:00:05,96 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:00:05,97 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 37.84400000004098. input_tokens=2690, output_tokens=418
12:00:10,445 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:00:10,446 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 39.08199999993667. input_tokens=2690, output_tokens=370
12:00:12,380 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:00:12,382 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 40.50300000002608. input_tokens=2690, output_tokens=222
12:00:14,285 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:00:14,286 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 41.08100000000559. input_tokens=2689, output_tokens=84
12:00:15,977 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:00:15,979 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 44.45600000000559. input_tokens=2691, output_tokens=491
12:00:17,314 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:00:17,315 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 46.337999999988824. input_tokens=34, output_tokens=529
12:00:21,521 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:00:21,522 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 47.3519999999553. input_tokens=2690, output_tokens=281
12:00:22,931 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:00:22,932 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 47.911000000080094. input_tokens=2689, output_tokens=261
12:00:26,10 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:00:26,11 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 49.65999999991618. input_tokens=34, output_tokens=299
12:00:29,252 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:00:29,253 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 53.57199999992736. input_tokens=2690, output_tokens=434
12:00:30,135 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:00:30,135 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 48.88099999981932. input_tokens=2690, output_tokens=98
12:00:33,703 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:00:33,704 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 56.40200000000186. input_tokens=2690, output_tokens=347
12:00:35,610 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:00:35,611 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 54.575999999884516. input_tokens=2689, output_tokens=384
12:00:36,979 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:00:36,980 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 50.99899999983609. input_tokens=2690, output_tokens=68
12:00:38,580 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:00:38,582 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 57.09599999990314. input_tokens=2691, output_tokens=199
12:00:41,8 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:00:41,9 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 54.674000000115484. input_tokens=2690, output_tokens=131
12:00:42,904 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:00:42,905 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 53.550000000046566. input_tokens=34, output_tokens=136
12:00:44,344 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:00:44,345 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 55.419999999925494. input_tokens=2690, output_tokens=197
12:00:50,551 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:00:50,552 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 59.51200000010431. input_tokens=2690, output_tokens=286
12:00:52,878 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:00:52,880 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 60.96999999997206. input_tokens=2689, output_tokens=301
12:00:54,28 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:00:54,29 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 59.8179999999702. input_tokens=2689, output_tokens=289
12:00:56,783 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:00:56,784 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 74.64099999982864. input_tokens=2690, output_tokens=705
12:00:59,202 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:00:59,203 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 59.52499999990687. input_tokens=2690, output_tokens=158
12:01:00,137 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:01:00,138 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 60.43599999998696. input_tokens=2690, output_tokens=132
12:01:03,377 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:01:03,378 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 52.93099999986589. input_tokens=2691, output_tokens=101
12:01:05,180 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:01:05,181 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 65.72800000011921. input_tokens=2690, output_tokens=389
12:01:09,552 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:01:09,553 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 64.4550000000745. input_tokens=2690, output_tokens=361
12:01:09,558 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:01:09,560 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 57.17699999990873. input_tokens=2689, output_tokens=280
12:01:13,126 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:01:13,128 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 58.8410000000149. input_tokens=2690, output_tokens=269
12:01:14,750 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:01:14,751 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 53.22799999988638. input_tokens=2690, output_tokens=106
12:01:16,930 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:01:16,931 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 53.99900000006892. input_tokens=2691, output_tokens=84
12:01:18,174 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:01:18,175 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 62.19500000006519. input_tokens=2690, output_tokens=361
12:01:19,193 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:01:19,194 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 49.94100000010803. input_tokens=2690, output_tokens=36
12:01:22,702 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:01:22,703 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 65.38699999987148. input_tokens=2690, output_tokens=348
12:01:24,875 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:01:24,876 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 51.170999999856576. input_tokens=2690, output_tokens=179
12:01:26,496 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:01:26,497 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 50.88500000000931. input_tokens=2691, output_tokens=102
12:01:29,703 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:01:29,705 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 51.123000000137836. input_tokens=2690, output_tokens=100
12:01:29,928 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:01:29,929 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 52.94900000002235. input_tokens=2690, output_tokens=146
12:01:31,790 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:01:31,791 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 65.77899999986403. input_tokens=2690, output_tokens=441
12:01:33,726 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:01:33,729 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 63.592000000178814. input_tokens=2690, output_tokens=416
12:01:36,962 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:01:36,963 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 54.057999999960884. input_tokens=2689, output_tokens=170
12:01:43,523 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:01:43,524 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 62.51399999996647. input_tokens=2690, output_tokens=419
12:01:44,901 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:01:44,904 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 60.5590000001248. input_tokens=2690, output_tokens=407
12:01:47,551 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:01:47,552 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 56.99900000006892. input_tokens=2690, output_tokens=442
12:01:48,827 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:01:48,828 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 54.79899999988265. input_tokens=2690, output_tokens=119
12:01:51,979 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:01:51,981 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 59.10000000009313. input_tokens=2691, output_tokens=448
12:01:53,106 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:01:53,107 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 56.32199999992736. input_tokens=2690, output_tokens=218
12:01:55,776 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:01:55,778 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 52.398999999975786. input_tokens=2689, output_tokens=101
12:01:57,852 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:01:57,853 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 52.67100000008941. input_tokens=34, output_tokens=179
12:01:58,699 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:01:58,701 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 59.49599999981001. input_tokens=34, output_tokens=381
12:01:59,750 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:01:59,751 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 50.19699999992736. input_tokens=34, output_tokens=149
12:02:03,371 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:02:03,372 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 50.243999999947846. input_tokens=34, output_tokens=169
12:02:05,30 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:02:05,31 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 50.27899999986403. input_tokens=34, output_tokens=173
12:02:06,55 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:02:06,56 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 56.49600000004284. input_tokens=34, output_tokens=259
12:02:10,154 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:02:10,155 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 50.95999999996275. input_tokens=34, output_tokens=158
12:02:12,886 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:02:12,887 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 50.18000000016764. input_tokens=2690, output_tokens=61
12:02:13,665 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:02:13,667 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 55.4910000001546. input_tokens=34, output_tokens=302
12:02:15,675 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:02:15,677 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 58.74500000011176. input_tokens=2690, output_tokens=404
12:02:18,500 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:02:18,501 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 52.002999999793246. input_tokens=34, output_tokens=186
12:02:24,376 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:02:24,378 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 54.67100000008941. input_tokens=34, output_tokens=338
12:02:26,280 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:02:26,281 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 56.351000000024214. input_tokens=34, output_tokens=307
12:02:28,432 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:02:28,434 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 63.55599999986589. input_tokens=34, output_tokens=607
12:02:30,179 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:02:30,181 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 58.38899999996647. input_tokens=34, output_tokens=219
12:02:33,943 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:02:33,944 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 56.97999999998137. input_tokens=34, output_tokens=169
12:02:36,494 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:02:36,496 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 62.765000000130385. input_tokens=34, output_tokens=311
12:02:41,422 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:02:41,423 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 57.89799999981187. input_tokens=2690, output_tokens=405
12:02:42,599 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:02:42,601 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 102.46100000012666. input_tokens=2691, output_tokens=1910
12:02:44,156 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:02:44,158 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 59.25300000002608. input_tokens=34, output_tokens=406
12:02:44,660 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:02:44,662 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 57.10899999993853. input_tokens=34, output_tokens=300
12:02:48,77 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:02:48,78 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 52.29899999988265. input_tokens=34, output_tokens=132
12:02:52,8 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:02:52,10 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 63.18099999986589. input_tokens=34, output_tokens=387
12:02:53,580 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:02:53,582 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 61.600999999791384. input_tokens=34, output_tokens=413
12:02:55,224 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:02:55,226 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 57.37199999997392. input_tokens=34, output_tokens=263
12:02:57,288 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:02:57,289 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 57.537000000011176. input_tokens=34, output_tokens=157
12:02:58,388 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:02:58,389 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 59.687999999849126. input_tokens=34, output_tokens=250
12:02:58,428 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:02:58,430 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 55.057999999960884. input_tokens=34, output_tokens=135
12:03:00,761 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:00,762 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 54.705000000074506. input_tokens=34, output_tokens=99
12:03:01,610 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:01,611 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 56.57899999991059. input_tokens=34, output_tokens=182
12:03:02,681 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:02,684 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 49.79399999999441. input_tokens=34, output_tokens=75
12:03:03,214 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:03,224 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 70.10800000000745. input_tokens=34, output_tokens=682
12:03:07,102 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:07,104 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 56.94800000009127. input_tokens=34, output_tokens=301
12:03:08,718 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:08,720 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 44.3410000000149. input_tokens=34, output_tokens=63
12:03:09,86 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:09,88 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 53.40999999991618. input_tokens=34, output_tokens=249
12:03:09,938 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:09,940 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 56.27199999988079. input_tokens=34, output_tokens=332
12:03:10,389 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:10,390 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 41.95699999993667. input_tokens=34, output_tokens=49
12:03:11,313 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:11,314 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 52.813000000081956. input_tokens=34, output_tokens=316
12:03:13,297 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:13,298 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 43.11599999992177. input_tokens=34, output_tokens=137
12:03:15,235 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:15,236 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 38.73999999999069. input_tokens=34, output_tokens=171
12:03:16,138 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:16,140 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 42.19500000006519. input_tokens=34, output_tokens=226
12:03:19,147 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:19,148 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 36.54600000008941. input_tokens=34, output_tokens=172
12:03:20,695 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:20,697 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 54.41399999987334. input_tokens=34, output_tokens=511
12:03:22,152 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:22,153 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 40.72899999981746. input_tokens=34, output_tokens=352
12:03:25,478 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:25,479 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 40.81400000001304. input_tokens=34, output_tokens=280
12:03:26,745 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:26,747 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 42.588999999919906. input_tokens=34, output_tokens=452
12:03:27,828 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:27,829 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 35.81800000020303. input_tokens=34, output_tokens=237
12:03:28,653 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:28,654 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 40.574999999953434. input_tokens=34, output_tokens=317
12:03:29,411 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:29,412 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 34.18599999998696. input_tokens=34, output_tokens=65
12:03:31,883 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:31,884 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 38.30099999997765. input_tokens=34, output_tokens=181
12:03:35,482 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:35,483 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 34.71999999997206. input_tokens=2691, output_tokens=104
12:03:37,799 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:37,801 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 40.510999999940395. input_tokens=2690, output_tokens=264
12:03:41,571 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:41,572 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 39.96000000019558. input_tokens=2690, output_tokens=179
12:03:42,650 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:42,651 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 44.21999999997206. input_tokens=2690, output_tokens=374
12:03:43,560 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:43,562 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 45.170999999856576. input_tokens=2691, output_tokens=435
12:03:43,991 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:43,992 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 41.3070000000298. input_tokens=2690, output_tokens=171
12:03:44,612 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:44,614 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 41.38899999996647. input_tokens=2690, output_tokens=59
12:03:50,968 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:50,970 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 42.25. input_tokens=2690, output_tokens=229
12:03:52,915 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:52,917 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 45.81099999998696. input_tokens=34, output_tokens=300
12:03:55,412 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:55,413 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 45.471999999834225. input_tokens=2690, output_tokens=350
12:03:58,654 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:03:58,657 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 49.566999999806285. input_tokens=34, output_tokens=492
12:04:00,453 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:04:00,454 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 47.15500000002794. input_tokens=34, output_tokens=191
12:04:03,173 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:04:03,174 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 51.85900000017136. input_tokens=2584, output_tokens=371
12:04:03,175 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:04:03,176 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 52.78499999991618. input_tokens=2690, output_tokens=405
12:04:05,39 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:04:05,40 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 23.4660000000149. input_tokens=34, output_tokens=82
12:04:05,679 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:04:05,680 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 30.195999999996275. input_tokens=34, output_tokens=215
12:04:07,725 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:04:07,726 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 24.162999999942258. input_tokens=34, output_tokens=94
12:04:07,912 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:04:07,913 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 30.110999999800697. input_tokens=34, output_tokens=212
12:04:12,3 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:04:12,4 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 56.76699999999255. input_tokens=34, output_tokens=579
12:04:12,289 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:04:12,290 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 27.673999999882653. input_tokens=34, output_tokens=200
12:04:13,369 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:04:13,371 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 30.718000000109896. input_tokens=34, output_tokens=377
12:04:14,784 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:04:14,786 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 30.792000000132248. input_tokens=34, output_tokens=313
12:04:17,537 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:04:17,538 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 26.565999999875203. input_tokens=34, output_tokens=238
12:04:19,510 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:04:19,512 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 16.334000000031665. input_tokens=34, output_tokens=290
12:04:20,661 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:04:20,662 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 25.24600000004284. input_tokens=34, output_tokens=414
12:04:22,265 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
12:04:22,267 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 19.079999999841675. input_tokens=34, output_tokens=449
12:04:22,273 datashaper.workflow.workflow INFO executing verb merge_graphs
12:04:22,293 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_extracted_entities.parquet
12:04:22,566 graphrag.index.run INFO Running workflow: create_final_covariates...
12:04:22,566 graphrag.index.run INFO dependencies for create_final_covariates: ['create_base_text_units']
12:04:22,566 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
12:04:22,574 datashaper.workflow.workflow INFO executing verb extract_covariates
12:04:22,751 datashaper.workflow.workflow INFO executing verb window
12:04:22,752 datashaper.workflow.workflow INFO executing verb genid
12:04:22,753 datashaper.workflow.workflow INFO executing verb convert
12:04:22,753 datashaper.workflow.workflow INFO executing verb rename
12:04:22,754 datashaper.workflow.workflow INFO executing verb select
12:04:22,756 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_covariates.parquet
12:04:23,5 graphrag.index.run INFO Running workflow: create_summarized_entities...
12:04:23,5 graphrag.index.run INFO dependencies for create_summarized_entities: ['create_base_extracted_entities']
12:04:23,5 graphrag.index.run INFO read table from storage: create_base_extracted_entities.parquet
12:04:23,8 datashaper.workflow.workflow INFO executing verb summarize_descriptions
12:04:23,11 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_summarized_entities.parquet
12:04:23,243 graphrag.index.run INFO Running workflow: join_text_units_to_covariate_ids...
12:04:23,243 graphrag.index.run INFO dependencies for join_text_units_to_covariate_ids: ['create_final_covariates']
12:04:23,243 graphrag.index.run INFO read table from storage: create_final_covariates.parquet
12:04:23,249 datashaper.workflow.workflow INFO executing verb select
12:04:23,249 datashaper.workflow.workflow INFO executing verb aggregate_override
12:04:23,258 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_covariate_ids.parquet
12:04:23,492 graphrag.index.run INFO Running workflow: create_base_entity_graph...
12:04:23,492 graphrag.index.run INFO dependencies for create_base_entity_graph: ['create_summarized_entities']
12:04:23,493 graphrag.index.run INFO read table from storage: create_summarized_entities.parquet
12:04:23,496 datashaper.workflow.workflow INFO executing verb cluster_graph
12:04:23,502 datashaper.workflow.workflow INFO executing verb select
12:04:23,503 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_entity_graph.parquet
12:04:23,738 graphrag.index.run INFO Running workflow: create_final_entities...
12:04:23,738 graphrag.index.run INFO dependencies for create_final_entities: ['create_base_entity_graph']
12:04:23,738 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
12:04:23,741 datashaper.workflow.workflow INFO executing verb unpack_graph
12:04:23,743 datashaper.workflow.workflow INFO executing verb rename
12:04:23,743 datashaper.workflow.workflow INFO executing verb select
12:04:23,744 datashaper.workflow.workflow INFO executing verb dedupe
12:04:23,744 datashaper.workflow.workflow INFO executing verb rename
12:04:23,745 datashaper.workflow.workflow INFO executing verb filter
12:04:23,748 datashaper.workflow.workflow INFO executing verb text_split
12:04:23,749 datashaper.workflow.workflow INFO executing verb drop
12:04:23,749 datashaper.workflow.workflow INFO executing verb merge
12:04:23,751 datashaper.workflow.workflow INFO executing verb text_embed
12:04:23,752 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=http://localhost:11434/v1
12:04:23,760 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for nomic-embed-text:latest: TPM=0, RPM=0
12:04:23,760 graphrag.index.llm.load_llm INFO create concurrency limiter for nomic-embed-text:latest: 25
12:04:23,760 graphrag.index.verbs.text.embed.strategies.openai INFO embedding 4 inputs via 4 snippets using 1 batches. max_batch_size=16, max_tokens=8191
12:04:24,803 httpx INFO HTTP Request: POST http://localhost:11434/v1/embeddings "HTTP/1.1 200 OK"
12:04:24,816 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.0560000000987202. input_tokens=121, output_tokens=0
12:04:24,820 datashaper.workflow.workflow INFO executing verb drop
12:04:24,821 datashaper.workflow.workflow INFO executing verb filter
12:04:24,827 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_entities.parquet
12:04:25,64 graphrag.index.run INFO Running workflow: create_final_nodes...
12:04:25,64 graphrag.index.run INFO dependencies for create_final_nodes: ['create_base_entity_graph']
12:04:25,64 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
12:04:25,67 datashaper.workflow.workflow INFO executing verb layout_graph
12:04:25,71 datashaper.workflow.workflow INFO executing verb unpack_graph
12:04:25,73 datashaper.workflow.workflow INFO executing verb unpack_graph
12:04:25,74 datashaper.workflow.workflow INFO executing verb drop
12:04:25,75 datashaper.workflow.workflow INFO executing verb filter
12:04:25,78 datashaper.workflow.workflow INFO executing verb select
12:04:25,79 datashaper.workflow.workflow INFO executing verb rename
12:04:25,79 datashaper.workflow.workflow INFO executing verb join
12:04:25,85 datashaper.workflow.workflow INFO executing verb convert
12:04:25,87 datashaper.workflow.workflow INFO executing verb rename
12:04:25,89 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_nodes.parquet
12:04:25,332 graphrag.index.run INFO Running workflow: create_final_communities...
12:04:25,332 graphrag.index.run INFO dependencies for create_final_communities: ['create_base_entity_graph']
12:04:25,332 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
12:04:25,335 datashaper.workflow.workflow INFO executing verb unpack_graph
12:04:25,337 datashaper.workflow.workflow INFO executing verb unpack_graph
12:04:25,338 datashaper.workflow.workflow INFO executing verb aggregate_override
12:04:25,340 datashaper.workflow.workflow INFO executing verb join
12:04:25,346 datashaper.workflow.workflow INFO executing verb join
12:04:25,351 datashaper.workflow.workflow INFO executing verb concat
12:04:25,351 datashaper.workflow.workflow INFO executing verb filter
12:04:25,355 datashaper.workflow.workflow INFO executing verb aggregate_override
12:04:25,358 datashaper.workflow.workflow INFO executing verb join
12:04:25,363 datashaper.workflow.workflow INFO executing verb filter
12:04:25,366 datashaper.workflow.workflow INFO executing verb fill
12:04:25,367 datashaper.workflow.workflow INFO executing verb merge
12:04:25,368 datashaper.workflow.workflow INFO executing verb copy
12:04:25,369 datashaper.workflow.workflow INFO executing verb select
12:04:25,371 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_communities.parquet
12:04:25,603 graphrag.index.run INFO Running workflow: join_text_units_to_entity_ids...
12:04:25,603 graphrag.index.run INFO dependencies for join_text_units_to_entity_ids: ['create_final_entities']
12:04:25,603 graphrag.index.run INFO read table from storage: create_final_entities.parquet
12:04:25,608 datashaper.workflow.workflow INFO executing verb select
12:04:25,609 datashaper.workflow.workflow INFO executing verb unroll
12:04:25,611 datashaper.workflow.workflow INFO executing verb aggregate_override
12:04:25,614 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_entity_ids.parquet
12:04:25,865 graphrag.index.run INFO Running workflow: create_final_relationships...
12:04:25,865 graphrag.index.run INFO dependencies for create_final_relationships: ['create_base_entity_graph', 'create_final_nodes']
12:04:25,865 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
12:04:25,870 graphrag.index.run INFO read table from storage: create_final_nodes.parquet
12:04:25,874 datashaper.workflow.workflow INFO executing verb unpack_graph
12:04:25,876 datashaper.workflow.workflow INFO executing verb filter
12:04:25,880 datashaper.workflow.workflow INFO executing verb rename
12:04:25,881 datashaper.workflow.workflow INFO executing verb filter
12:04:25,884 datashaper.workflow.workflow INFO executing verb drop
12:04:25,884 datashaper.workflow.workflow INFO executing verb compute_edge_combined_degree
12:04:25,888 datashaper.workflow.workflow INFO executing verb convert
12:04:25,888 datashaper.workflow.workflow INFO executing verb convert
12:04:25,890 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_relationships.parquet
12:04:26,144 graphrag.index.run INFO Running workflow: join_text_units_to_relationship_ids...
12:04:26,144 graphrag.index.run INFO dependencies for join_text_units_to_relationship_ids: ['create_final_relationships']
12:04:26,145 graphrag.index.run INFO read table from storage: create_final_relationships.parquet
12:04:26,148 datashaper.workflow.workflow INFO executing verb select
12:04:26,149 datashaper.workflow.workflow INFO executing verb unroll
12:04:26,150 datashaper.workflow.workflow INFO executing verb aggregate_override
12:04:26,152 datashaper.workflow.workflow INFO executing verb select
12:04:26,154 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_relationship_ids.parquet
12:04:26,385 graphrag.index.run INFO Running workflow: create_final_community_reports...
12:04:26,385 graphrag.index.run INFO dependencies for create_final_community_reports: ['create_final_relationships', 'create_final_covariates', 'create_final_nodes']
12:04:26,385 graphrag.index.run INFO read table from storage: create_final_relationships.parquet
12:04:26,389 graphrag.index.run INFO read table from storage: create_final_covariates.parquet
12:04:26,396 graphrag.index.run INFO read table from storage: create_final_nodes.parquet
12:04:26,399 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
12:04:26,400 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
12:04:26,401 datashaper.workflow.workflow INFO executing verb prepare_community_reports_claims
12:04:26,404 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
12:04:26,408 datashaper.workflow.workflow INFO executing verb prepare_community_reports
12:04:26,408 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 4
12:04:26,428 datashaper.workflow.workflow INFO executing verb create_community_reports
12:04:26,431 datashaper.workflow.workflow INFO executing verb window
12:04:26,433 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_community_reports.parquet
12:04:26,680 graphrag.index.run INFO Running workflow: create_final_text_units...
12:04:26,680 graphrag.index.run INFO dependencies for create_final_text_units: ['join_text_units_to_entity_ids', 'create_base_text_units', 'join_text_units_to_relationship_ids', 'join_text_units_to_covariate_ids']
12:04:26,680 graphrag.index.run INFO read table from storage: join_text_units_to_entity_ids.parquet
12:04:26,683 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
12:04:26,687 graphrag.index.run INFO read table from storage: join_text_units_to_relationship_ids.parquet
12:04:26,689 graphrag.index.run INFO read table from storage: join_text_units_to_covariate_ids.parquet
12:04:26,692 datashaper.workflow.workflow INFO executing verb select
12:04:26,693 datashaper.workflow.workflow INFO executing verb rename
12:04:26,693 datashaper.workflow.workflow INFO executing verb join
12:04:26,701 datashaper.workflow.workflow INFO executing verb join
12:04:26,707 datashaper.workflow.workflow INFO executing verb join
12:04:26,712 datashaper.workflow.workflow INFO executing verb aggregate_override
12:04:26,714 datashaper.workflow.workflow INFO executing verb select
12:04:26,716 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_text_units.parquet
12:04:26,961 graphrag.index.run INFO Running workflow: create_base_documents...
12:04:26,961 graphrag.index.run INFO dependencies for create_base_documents: ['create_final_text_units']
12:04:26,961 graphrag.index.run INFO read table from storage: create_final_text_units.parquet
12:04:26,966 datashaper.workflow.workflow INFO executing verb unroll
12:04:26,968 datashaper.workflow.workflow INFO executing verb select
12:04:26,970 datashaper.workflow.workflow INFO executing verb rename
12:04:26,970 datashaper.workflow.workflow INFO executing verb join
12:04:26,977 datashaper.workflow.workflow INFO executing verb aggregate_override
12:04:26,979 datashaper.workflow.workflow INFO executing verb join
12:04:26,984 datashaper.workflow.workflow INFO executing verb rename
12:04:26,985 datashaper.workflow.workflow INFO executing verb convert
12:04:26,990 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_documents.parquet
12:04:27,234 graphrag.index.run INFO Running workflow: create_final_documents...
12:04:27,234 graphrag.index.run INFO dependencies for create_final_documents: ['create_base_documents']
12:04:27,234 graphrag.index.run INFO read table from storage: create_base_documents.parquet
12:04:27,239 datashaper.workflow.workflow INFO executing verb rename
12:04:27,241 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_documents.parquet
